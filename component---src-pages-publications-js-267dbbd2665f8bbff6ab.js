(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{"+QRC":function(e,n,t){"use strict";t("pIFo");var a=t("E9nw"),o="Copy to clipboard: #{key}, Enter";e.exports=function(e,n){var t,i,r,s,l,c,d=!1;n||(n={}),t=n.debug||!1;try{if(r=a(),s=document.createRange(),l=document.getSelection(),(c=document.createElement("span")).textContent=e,c.style.all="unset",c.style.position="fixed",c.style.top=0,c.style.clip="rect(0, 0, 0, 0)",c.style.whiteSpace="pre",c.style.webkitUserSelect="text",c.style.MozUserSelect="text",c.style.msUserSelect="text",c.style.userSelect="text",c.addEventListener("copy",(function(t){t.stopPropagation(),n.format&&(t.preventDefault(),t.clipboardData.clearData(),t.clipboardData.setData(n.format,e))})),document.body.appendChild(c),s.selectNodeContents(c),l.addRange(s),!document.execCommand("copy"))throw new Error("copy command was unsuccessful");d=!0}catch(u){t&&console.error("unable to copy using execCommand: ",u),t&&console.warn("trying IE specific stuff");try{window.clipboardData.setData(n.format||"text",e),d=!0}catch(u){t&&console.error("unable to copy using clipboardData: ",u),t&&console.error("falling back to prompt"),i=function(e){var n=(/mac os x/i.test(navigator.userAgent)?"⌘":"Ctrl")+"+C";return e.replace(/#{\s*key\s*}/g,n)}("message"in n?n.message:o),window.prompt(i,e)}}finally{l&&("function"==typeof l.removeRange?l.removeRange(s):l.removeAllRanges()),c&&document.body.removeChild(c),r()}return d}},"4IYq":function(e,n,t){"use strict";t.r(n);t("rGqo"),t("yt8O"),t("Btvt"),t("RW0V");var a=t("q1tI"),o=t.n(a),i=t("M8b6"),r=(t("f3/d"),t("P5Jw")),s=t("30+C"),l=t("50B7"),c=t("o4QW"),d=t("IP2g"),u=t("wHSu"),p=t("Z3vd"),g=t("9jPY"),h=function(e){return o.a.createElement(s.a,{style:{width:"100%",marginBottom:"15px",padding:"10px",minWidth:"1000px"}},o.a.createElement(l.a,{title:e.name,subheader:e.authors,titleTypographyProps:{variant:"h5"}}),o.a.createElement(c.a,null,""===e.paper?o.a.createElement(p.a,{variant:"contained",style:{background:"#CED9E0",color:"#ffff",textShadow:"none"},disabled:!0},"Download Paper",o.a.createElement(d.a,{icon:u.b,style:{marginLeft:"10px"}})):o.a.createElement(p.a,{variant:"contained",style:{background:"#232F34",color:"#ffff",textShadow:"none"},href:e.paper,target:"_blank",rel:"noopener"},"Download Paper",o.a.createElement(d.a,{icon:u.b,style:{marginLeft:"10px"}})),""===e.bibtext?o.a.createElement(p.a,{variant:"contained",style:{background:"#CED9E0",color:"#ffff",textShadow:"none"},disabled:!0},"Copy Bibtex",o.a.createElement(d.a,{icon:u.a,style:{marginLeft:"10px"}})):o.a.createElement(r.CopyToClipboard,{text:e.bibtext},o.a.createElement("span",null,o.a.createElement(p.a,{variant:"contained",style:{background:"#232F34",color:"#ffff",textShadow:"none"}},"Copy Bibtex",o.a.createElement(d.a,{icon:u.a,style:{marginLeft:"10px"}})))),""===e.code?o.a.createElement(p.a,{variant:"contained",style:{background:"#CED9E0",color:"#ffff",textShadow:"none"},disabled:!0},"Code",o.a.createElement(d.a,{icon:u.d,style:{marginLeft:"10px"}})):o.a.createElement(p.a,{variant:"contained",style:{background:"#232F34",color:"#ffff",textShadow:"none"},href:e.code,target:"_blank",rel:"noopener"},"Code",o.a.createElement(d.a,{icon:u.d,style:{marginLeft:"10px"}}))),o.a.createElement(g.a,{label:e.venue,size:"small",style:{background:"#232F34",color:"#ffff",textShadow:"none",fontSize:"12px",float:"right"}}))},m=t("5Uy0");n.default=function(){return o.a.createElement("div",{style:{margin:"5rem auto",maxWidth:1e3}},o.a.createElement(i.a,null),o.a.createElement("div",{style:{display:"flex",flexWrap:"wrap"}},Object.keys(m).reverse().map((function(e,n){return o.a.createElement("div",{key:n},o.a.createElement("h1",null,e),Object.keys(m[e]).map((function(n,t){return o.a.createElement(h,{key:n,name:n,venue:m[e][n].venue,authors:m[e][n].authors,paper:m[e][n].paper,bibtext:m[e][n].bibtext,code:m[e][n].code})})))}))))}},"5Uy0":function(e){e.exports=JSON.parse('{"2008":{"A Generative Model for Parsing Natural Language to Meaning Representations":{"venue":"EMNLP","authors":"Wei Lu, Hwee Tou Ng, Wee Sun Lee and Luke S. Zettlemoyer","paper":"http://statnlp.com/people/luwei/publications/emnlp08lnlz.pdf","bibtext":"@inproceedings{lu2008generative,\\ntitle={A generative model for parsing natural language to meaning representations},\\nauthor={Lu, Wei and Ng, Hwee Tou and Lee, Wee Sun and Zettlemoyer, Luke S},\\nbooktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},\\npages={783--792},\\nyear={2008},\\norganization={Association for Computational Linguistics}\\n}","code":"http://statnlp.com/people/luwei/code/hybridtree.r.2010.12.19.tgz"}},"2009":{"Natural Language Generation with Tree Conditional Random Fields":{"venue":"EMNLP","authors":"Wei Lu, Hwee Tou Ng and Wee Sun Lee","paper":"http://statnlp.com/people/luwei/publications/emnlp09lnl.pdf","bibtext":"@inproceedings{lu2009natural,\\ntitle={Natural language generation with tree conditional random fields},\\nauthor={Lu, Wei and Ng, Hwee Tou and Lee, Wee Sun},\\nbooktitle={Proceedings of the 2009 Conference on Empirical Methods in Natural Language\\nProcessing: Volume 1-Volume 1},\\npages={400--409},\\nyear={2009},\\norganization={Association for Computational Linguistics}\\n}","code":""}},"2010":{"Better Punctuation Prediction with Dynamic Conditional Random Fields":{"venue":"EMNLP","authors":"Wei Lu and Hwee Tou Ng","paper":"http://statnlp.com/people/luwei/publications/emnlp10ln.pdf","bibtext":"@inproceedings{lu2010better,\\ntitle={Better punctuation prediction with dynamic conditional random fields},\\nauthor={Lu, Wei and Ng, Hwee Tou},\\nbooktitle={Proceedings of the 2010 conference on empirical methods in natural language\\nprocessing},\\npages={177--186},\\nyear={2010},\\norganization={Association for Computational Linguistics}\\n}","code":"http://statnlp.com/people/luwei/code/punct.rar"}},"2011":{"A Probabilistic Forest-to-String Model for Language Generation from Typed Lambda Calculus Expressions":{"venue":"EMNLP","authors":"Wei Lu and Hwee Tou Ng","paper":"http://statnlp.com/people/luwei/publications/emnlp11ln.pdf","bibtext":"@inproceedings{lu2011probabilistic,\\ntitle={A probabilistic forest-to-string model for language generation from typed lambda calculus\\nexpressions},\\nauthor={Lu, Wei and Ng, Hwee Tou},\\nbooktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing},\\npages={1611--1622},\\nyear={2011},\\norganization={Association for Computational Linguistics}\\n}","code":"http://statnlp.com/people/luwei/code/lambdagen.20111015.tar.gz"}},"2012":{"Automatic Event Extraction with Structured Preference Modeling":{"venue":"ACL","authors":"Wei Lu and Dan Roth","paper":"http://statnlp.com/people/luwei/publications/acl12lr.pdf","bibtext":"@inproceedings{lu2012automatic,\\ntitle={Automatic event extraction with structured preference modeling},\\nauthor={Lu, Wei and Roth, Dan},\\nbooktitle={Proceedings of the 50th Annual Meeting of the Association for Computational\\nLinguistics: Long Papers-Volume 1},\\npages={835--844},\\nyear={2012},\\norganization={Association for Computational Linguistics}\\n}","code":""},"Joint Inference for Event Timeline Construction":{"venue":"EMNLP","authors":"Quang Do,  Wei Lu, and Dan Roth","paper":"http://statnlp.com/people/luwei/publications/emnlp12dlr.pdf","bibtext":"@inproceedings{do2012joint,\\ntitle={Joint inference for event timeline construction},\\nauthor={Do, Quang Xuan and Lu, Wei and Roth, Dan},\\nbooktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language\\nProcessing\\nand Computational Natural Language Learning},\\npages={677--687},\\nyear={2012},\\norganization={Association for Computational Linguistics}\\n}","code":""}},"2014":{"Semantic Parsing with Relaxed Hybrid Trees":{"venue":"EMNLP","authors":"Wei Lu","paper":"https://www.aclweb.org/anthology/D14-1137","bibtext":"@InProceedings{lu:2014:EMNLP2014,\\nauthor    = {Lu, Wei},\\ntitle     = {Semantic Parsing with Relaxed Hybrid Trees},\\nbooktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language\\nProcessing (EMNLP)},\\nmonth     = {October},\\nyear      = {2014},\\naddress   = {Doha, Qatar},\\npublisher = {Association for Computational Linguistics},\\npages     = {1308--1318},\\nurl       = {http://www.aclweb.org/anthology/D14-1137}\\n}","code":"http://www.statnlp.org/paper/constrained-semantic-forests-for-improved-discriminative-semantic-parsing.html"}},"2015":{"Joint Mention Extraction and Classification with Mention Hypergraphs":{"venue":"EMNLP","authors":"Wei Lu and Dan Roth","paper":"https://www.aclweb.org/anthology/D15-1102","bibtext":"@InProceedings{lu-roth:2015:EMNLP,\\nauthor    = {Lu, Wei  and  Roth, Dan},\\ntitle     = {Joint Mention Extraction and Classification with Mention Hypergraphs},\\nbooktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language\\nProcessing},\\nmonth     = {September},\\nyear      = {2015},\\naddress   = {Lisbon, Portugal},\\npublisher = {Association for Computational Linguistics},\\npages     = {857--867},\\nurl       = {http://aclweb.org/anthology/D15-1102}\\n}","code":"http://www.statnlp.org/research/ie/code/statnlp-mentionextraction.v0.2.tgz"},"Constrained Semantic Forests for Improved Discriminative Semantic Parsing":{"venue":"ACL-IJCNLP","authors":"Wei Lu","paper":"https://www.aclweb.org/anthology/P15-2121","bibtext":"@inproceedings{lu2015constrained,\\ntitle={Constrained Semantic Forests for Improved Discriminative Semantic Parsing.},\\nauthor={Lu, Wei},\\nbooktitle={ACL (2)},\\npages={737--742},\\nyear={2015}\\n}","code":"http://www.statnlp.org/research/sp/code/sp.v0.2.tgz"},"GraRep: Learning Graph Representations with Global Structural Information":{"venue":"CIKM","authors":"Shaosheng Cao, Wei Lu and Qiongkai Xu","paper":"https://dl.acm.org/citation.cfm?id=2806512&dl=ACM&coll=DL","bibtext":"@inproceedings{cao2015grarep,\\ntitle={Grarep: Learning graph representations with global structural information},\\nauthor={Cao, Shaosheng and Lu, Wei and Xu, Qiongkai},\\nbooktitle={Proceedings of the 24th ACM International on Conference on Information and Knowledge\\nManagement},\\npages={891--900},\\nyear={2015},\\norganization={ACM}\\n}","code":"https://github.com/ShelsonCao/GraRep"}},"2016":{"A General Regularization Framework for Domain Adaptation":{"venue":"EMNLP","authors":"Wei Lu, Hai Leong Chieu and Jonathan Löfgren","paper":"http://www.statnlp.org/research/ml/emnlp2016-720.pdf","bibtext":"@inproceedings{lu2016general,\\ntitle={A General Regularization Framework for Domain Adaptation.},\\nauthor={Lu, Wei and Chieu, Hai Leong and L{\\"o}fgren, Jonathan},\\nbooktitle={EMNLP},\\npages={950--954},\\nyear={2016}\\n}","code":"http://www.statnlp.org/research/ml/code/emnlp-domain-adaptation.tar.gz"},"Learning to Capitalize with Character-Level Recurrent Neural Networks: An Empirical Study":{"venue":"EMNLP","authors":"Raymond Hendy Susanto, Hai Leong Chieu and Wei Lu","paper":"http://www.statnlp.org/research/ta/rnn_truecase.pdf","bibtext":"@InProceedings{susanto-chieu-lu:2016:EMNLP2016,\\nauthor    = {Susanto, Raymond Hendy  and  Chieu, Hai Leong  and  Lu, Wei},\\ntitle     = {Learning to Capitalize with Character-Level Recurrent Neural Networks: An Empirical\\nStudy},\\nbooktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language\\nProcessing},\\nmonth     = {November},\\nyear      = {2016},\\naddress   = {Austin, Texas},\\npublisher = {Association for Computational Linguistics},\\npages     = {2090--2095},\\nurl       = {https://aclweb.org/anthology/D16-1225}\\n}","code":"https://gitlab.com/raymondhs/char-rnn-truecase"},"Learning to Recognize Discontiguous Entities":{"venue":"EMNLP","authors":"Aldrian Obaja Muis and Wei Lu","paper":"http://www.statnlp.org/research/ie/emnlp2016-discontiguous-entities.pdf","bibtext":"@inproceedings{muis2016learning,\\ntitle={Learning to Recognize Discontiguous Entities.},\\nauthor={Muis, Aldrian Obaja and Lu, Wei},\\nbooktitle={EMNLP},\\npages={75--84},\\nyear={2016}\\n}","code":"http://www.statnlp.org/research/ie/code/learning-to-recognize-discontiguous-entities-code.zip"},"Improving Semantic Parsing with Enriched Synchronous Context-Free Grammars in Statistical Machine Translation":{"venue":"TALLIP","authors":"Junhui Li, Muhua Zhu,  Wei Lu, and Guodong Zhou","paper":"https://dl.acm.org/citation.cfm?id=2963099","bibtext":"@article{li2016improving,title={Improving Semantic Parsing with Enriched Synchronous Context-Free Grammars in Statistical\\nMachine Translation},\\nauthor={Li, Junhui and Zhu, Muhua and Lu, Wei and Zhou, Guodong},\\njournal={ACM Transactions on Asian and Low-Resource Language Information Processing (TALLIP)},\\nvolume={16},\\nnumber={1},\\npages={6},\\nyear={2016},\\npublisher={ACM}\\n}\\near={2015} }","code":""},"Weak Semi-Markov CRFs for NP Chunking in Informal Text":{"venue":"NAACL","authors":"Aldrian Obaja Muis and Wei Lu","paper":"https://arxiv.org/abs/1810.08567","bibtext":"@InProceedings{muis-lu:2016:N16-1,\\nauthor    = {Muis, Aldrian Obaja  and  Lu, Wei},\\ntitle     = {Weak Semi-Markov CRFs for Noun Phrase Chunking in Informal Text},\\nbooktitle = {Proceedings of the 2016 Conference of the North American Chapter of the Association\\nfor Computational Linguistics: Human Language Technologies},\\nmonth     = {June},\\nyear      = {2016},\\naddress   = {San Diego, California},\\npublisher = {Association for Computational Linguistics},\\npages     = {714--719},\\nurl       = {http://www.aclweb.org/anthology/N16-1085}\\n}","code":"http://statnlp.org/research/ie/code/weak-semi-crf-in-informal-text-code.zip"},"Deep Neural Networks for Learning Graph Representations":{"venue":"AAAI","authors":"Shaosheng Cao, Wei Lu and Qiongkai Xu","paper":"https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12423/11715","bibtext":"@inproceedings{cao2016deep,\\ntitle={Deep neural networks for learning graph representations},\\nauthor={Cao, Shaosheng and Lu, Wei and Xu, Qiongkai},\\nbooktitle={Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},\\npages={1145--1152},\\nyear={2016},\\norganization={AAAI Press}\\n}","code":"https://github.com/ShelsonCao/DNGR"}},"2017":{"Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators":{"venue":"EMNLP","authors":"Aldrian Obaja Muis and Wei Lu","paper":"http://www.statnlp.org/research/ie/emnlp2017-mention-separators.pdf","bibtext":"@InProceedings{muis-lu:2017:EMNLP2017,\\nauthor    = {Muis, Aldrian Obaja  and  Lu, Wei},\\ntitle     = {Labeling Gaps Between Words: Recognizing Overlapping Mentions with Mention Separators},\\nbooktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},\\nmonth     = {September},\\nyear      = {2017},\\naddress   = {Copenhagen, Denmark},\\npublisher = {Association for Computational Linguistics},\\npages     = {2598--2608},\\nabstract  = {In this paper, we propose a new model that is capable of recognizing\\noverlapping mentions. We introduce a novel notion of mention separators that\\ncan be effectively used to capture how mentions overlap with one another. On\\ntop of a novel multigraph representation that we introduce, we show that\\nefficient and exact inference can still be performed. We present some\\ntheoretical analysis on the differences between our model and a recently\\nproposed model for recognizing overlapping mentions, and discuss the possible\\nimplications of the differences. Through extensive empirical analysis on\\nstandard datasets, we demonstrate the effectiveness of our approach.},\\nurl       = {https://www.aclweb.org/anthology/D17-1275}\\n}","code":"https://gitlab.com/sutd_nlp/overlapping_mentions"},"A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings":{"venue":"EMNLP","authors":"Wei Yang, Wei Lu and Vincent Zheng","paper":"https://www.aclweb.org/anthology/D17-1312","bibtext":"@InProceedings{yang-lu-zheng:2017:EMNLP2017,\\nauthor    = {Yang, Wei  and  Lu, Wei  and  Zheng, Vincent},\\ntitle     = {A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings},\\nbooktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},\\nmonth     = {September},\\nyear      = {2017},\\naddress   = {Copenhagen, Denmark},\\npublisher = {Association for Computational Linguistics},\\npages     = {2888--2894},\\nabstract  = {Learning word embeddings has received a significant amount of attention\\nrecently. Often, word embeddings are learned in an unsupervised manner from a\\nlarge collection of text. The genre of the text typically plays an important\\nrole in the effectiveness of the resulting embeddings. How to effectively train\\nword embedding models using data from different domains remains a problem that\\nis less explored. In this paper, we present a simple yet effective method for\\nlearning word embeddings based on text from different domains. We demonstrate\\nthe effectiveness of our approach through extensive experiments on various\\ndown-stream NLP tasks.},\\nurl       = {https://www.aclweb.org/anthology/D17-1311}\\n}","code":"https://github.com/Victor0118/cross_domain_embedding"},"Topical Coherence in LDA-based Models through Induced Segmentation":{"venue":"ACL","authors":"Hesam Amoualian, Wei Lu, Eric Gaussier, Massih R Amini, Georgios Balikas and Marianne Clausel","paper":"https://www.aclweb.org/anthology/P17-1165","bibtext":"@InProceedings{amoualian-EtAl:2017:Long,\\nauthor    = {Amoualian, Hesam  and  Lu, Wei  and  Gaussier, Eric  and  Balikas, Georgios  and\\nAmini, Massih R  and  Clausel, Marianne},\\ntitle     = {Topical Coherence in LDA-based Models through Induced Segmentation},\\nbooktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers)},\\nmonth     = {July},\\nyear      = {2017},\\naddress   = {Vancouver, Canada},\\npublisher = {Association for Computational Linguistics},\\npages     = {1799--1809},\\nabstract  = {This paper presents an LDA-based model that generates topically coherent\\nsegments within documents by jointly segmenting documents and assigning topics\\nto their words. The coherence between topics is ensured through a copula,\\nbinding the topics associated to the words of a segment. In addition, this\\nmodel relies on both document and segment specific topic distributions so as to\\ncapture fine grained differences in topic assignments. We show that the\\nproposed model naturally encompasses other state-of-the-art LDA-based models\\ndesigned for similar tasks. Furthermore, our experiments, conducted on six\\ndifferent publicly available datasets, show the effectiveness of our model in\\nterms of perplexity, Normalized Pointwise Mutual Information, which captures\\nthe coherence between the generated topics, and the Micro F1 measure for text\\nclassification.},\\nurl       = {http://aclweb.org/anthology/P17-1165}\\n}","code":""},"Neural Architectures for Multilingual Semantic Parsing":{"venue":"ACL","authors":"Raymond Hendy Susanto and Wei Lu","paper":"https://www.aclweb.org/anthology/P17-2007","bibtext":"@InProceedings{susanto-lu:2017:Short,\\nauthor    = {Susanto, Raymond Hendy  and  Lu, Wei},\\ntitle     = {Neural Architectures for Multilingual Semantic Parsing},\\nbooktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational\\nLinguistics (Volume 2: Short Papers)},\\nmonth     = {July},\\nyear      = {2017},\\naddress   = {Vancouver, Canada},\\npublisher = {Association for Computational Linguistics},\\npages     = {38--44},\\nabstract  = {In this paper, we address semantic parsing in a multilingual context. We train\\none multilingual model that is capable of parsing natural language sentences\\nfrom multiple different languages into their corresponding formal semantic\\nrepresentations. We extend an existing sequence-to-tree model to a multi-task\\nlearning framework which shares the decoder for generating semantic\\nrepresentations. We report evaluation results on the multilingual GeoQuery\\ncorpus and introduce a new multilingual version of the ATIS corpus.},\\nurl       = {http://aclweb.org/anthology/P17-2007}\\n}","code":"https://github.com/raymondhs/semantic-multi"},"MalwareTextDB: A Database for Annotated Malware Articles":{"venue":"ACL","authors":"Swee Kiat Lim, Aldrian Obaja Muis, Wei Lu and Chen Hui Ong","paper":"https://www.aclweb.org/anthology/P17-1143","bibtext":"@InProceedings{lim-EtAl:2017:Long,\\nauthor    = {Lim, Swee Kiat  and  Muis, Aldrian Obaja  and  Lu, Wei  and  Ong, Chen Hui},\\ntitle     = {MalwareTextDB: A Database for Annotated Malware Articles},\\nbooktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers)},\\nmonth     = {July},\\nyear      = {2017},\\naddress   = {Vancouver, Canada},\\npublisher = {Association for Computational Linguistics},\\npages     = {1557--1567},\\nabstract  = {Cybersecurity risks and malware threats are becoming increasingly dangerous and\\ncommon. Despite the severity of the problem, there has been few NLP efforts\\nfocused on tackling cybersecurity.\\nIn this paper, we discuss the construction of a new database for annotated\\nmalware texts. An annotation framework is introduced based on the MAEC\\nvocabulary for defining malware characteristics, along with a database\\nconsisting of 39 annotated APT reports with a total of 6,819 sentences. We also\\nuse the database to construct models that can potentially help cybersecurity\\nresearchers in their data collection and analytics efforts.},\\nurl       = {http://aclweb.org/anthology/P17-1143}\\n}","code":"http://www.statnlp.org/research/re/MalwareTextDB-1.0-experiments.zip"},"Efficient Dependency-guided Named Entity Recognition":{"venue":"AAAI","authors":"Zhanming Jie, Aldrian Obaja Muis, and  Wei Lu","paper":"https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14741","bibtext":"@inproceedings{jie2017efficient,\\ntitle={Efficient Dependency-Guided Named Entity Recognition.},\\nauthor={Jie, Zhanming and Muis, Aldrian Obaja and Lu, Wei},\\nbooktitle={AAAI},\\npages={3457--3465},\\nyear={2017}\\n}","code":"https://gitlab.com/allanjie/dependeny-guided-ner"},"Learning Latent Sentiment Scopes for Entity-Level Sentiment Analysis":{"venue":"AAAI","authors":"Hao Li and Wei Lu","paper":"https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14931","bibtext":"@inproceedings{li2017learning,\\ntitle={Learning Latent Sentiment Scopes for Entity-Level Sentiment Analysis.},\\nauthor={Li, Hao and Lu, Wei},\\nbooktitle={AAAI},\\npages={3482--3489},\\nyear={2017}\\n}","code":"https://github.com/leodotnet/sentimentscope"},"Semantic Parsing with Neural Hybrid Trees":{"venue":"AAAI","authors":"Raymond Hendy Susanto and Wei Lu","paper":"https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14843","bibtext":"@inproceedings{susanto2017semantic,\\ntitle={Semantic Parsing with Neural Hybrid Trees.},\\nauthor={Susanto, Raymond Hendy and Lu, Wei},\\nbooktitle={AAAI},\\npages={3309--3315},\\nyear={2017}\\n}","code":"https://gitlab.com/raymondhs/statnlp-sp-neural/"},"Improving Word Embeddings with Convolutional Feature Learning and Subword Information":{"venue":"AAAI","authors":"Shaosheng Cao and Wei Lu","paper":"https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14724","bibtext":"@inproceedings{cao2017improving,\\ntitle={Improving Word Embeddings with Convolutional Feature Learning and Subword Information.},\\nauthor={Cao, Shaosheng and Lu, Wei},\\nbooktitle={AAAI},\\npages={3144--3151},\\nyear={2017}\\n}","code":"https://github.com/ShelsonCao/IWE"}},"2018":{"Neural Segmental Hypergraphs for Overlapping Mention Recognition":{"venue":"EMNLP","authors":"Bailin Wang and Wei Lu","paper":"http://www.statnlp.org/research/ie/emnlp2018-semi.pdf","bibtext":"","code":"https://github.com/berlino/overlapping-ner-em18"},"A Neural Transition-based Model for Nested Mention Recognition":{"venue":"EMNLP","authors":"Bailin Wang, Wei Lu, Yu Wang and Hongxia Jin","paper":"http://www.statnlp.org/research/ie/emnlp2018-transition.pdf","bibtext":"","code":"https://github.com/berlino/nest-trans-em18"},"Better Transition-Based AMR Parsing with a Refined Search Space":{"venue":"EMNLP","authors":"Zhijiang Guo and Wei Lu","paper":"http://www.statnlp.org/research/sp/zhijiang18emnlp.pdf","bibtext":"@InProceedings{D18-1198,\\nauthor = \\"Guo, Zhijiang and Lu, Wei\\",\\ntitle = \\"Better Transition-Based AMR Parsing with a Refined Search Space\\",\\nbooktitle = \\"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\\",\\nyear = \\"2018\\"\\n}","code":"https://github.com/Cartus/AMR-Parser"},"Dependency-based Hybrid Trees for Semantic Parsing":{"venue":"EMNLP","authors":"Zhanming Jie and Wei Lu","paper":"https://arxiv.org/abs/1809.00107","bibtext":"@InProceedings{jie2018dependency,\\nauthor = {Jie Zhanming and Lu, Wei},\\ntitle = {Dependency-based Hybrid Trees for Semantic Parsing},\\nbooktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},\\naddress = {Brussels, Belgium},\\nyear = {2018}\\n}","code":"https://github.com/allanj/dep-hybrid-tree"},"Neural Adaptation Layers for Cross-domain Named Entity Recognition":{"venue":"EMNLP","authors":"Bill Yuchen Lin and Wei Lu","paper":"http://yuchenlin.xyz/paper/emnlp2018_cdma-ner_sm.pdf","bibtext":"@InProceedings{bylin-18-nalner,\\nauthor = {Bill Yuchen, Lin and Wei, Lu},\\ntitle = {Neural Adaptation Layers for Cross-domain Named Entity Recognition},\\nbooktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},\\nmonth = {November},\\nyear = {2018},\\naddress = {Brussels, Belgium},\\npublisher = {Association for Computational Linguistics},\\n}","code":"https://github.com/yuchenlin/CDMA-NER"},"Learning with Structured Representations for Negation Scope Extraction":{"venue":"ACL","authors":"Hao Li and Wei Lu","paper":"http://www.statnlp.org/research/st/acl2018-negationscope.pdf","bibtext":"@InProceedings{haonegation,\\nauthor    = {Li, Hao and Lu, Wei},\\ntitle     = {Learning with Structured Representations for Negation Scope Extraction},\\nbooktitle = {Proceedings of the 56th Annual Meeting of the Association for Computation Linguistics},\\naddress   = {Melbourne, Australia},\\nyear      = {2018}\\n}","code":"https://github.com/leodotnet/negationscope"},"Learning Cross-lingual Distributed Logical Representations for Semantic Parsing":{"venue":"ACL","authors":"Yanyan Zou and Wei Lu","paper":"http://www.statnlp.org/wp-content/uploads/papers/2018/learning-crosslingual/acl2018.pdf","bibtext":"@InProceedings{zou2018crosslingual,\\nauthor    = {Yanyan Zou and Lu, Wei},\\ntitle     = {Learning Cross-lingual Distributed Logical Representations for Semantic Parsing},\\nbooktitle = {Proceedings of the 56th Annual Meeting of the Association for Computation Linguistics},\\naddress   = {Melbourne, Australia},\\nyear      = {2018}\\n}","code":"https://github.com/zoezou2015/cross-lingual-embedding"},"SemEval-2018 Task 8: Semantic Extraction from CybersecUrity REports using Natural Language Processing (SecureNLP)":{"venue":"SemEval","authors":"Peter Phandi, Amila Silva, and Wei Lu","paper":"https://aclweb.org/anthology/S18-1113","bibtext":"@InProceedings{SemEval2018Task8,\\nauthor    = {Phandi, Peter and Silva, Amila and Lu, Wei},\\ntitle     = {SemEval-2018 {T}ask 8: {S}emantic {E}xtraction from {C}ybersec{U}rity {RE}ports\\nusing {N}atural {L}anguage {P}rocessing ({S}ecure{NLP})},\\nbooktitle = {Proceedings of International Workshop on Semantic Evaluation (SemEval-2018)},\\naddress   = {New Orleans, LA, USA},\\nyear      = {2018}\\n}","code":""},"cw2vec: Learning Chinese Word Embeddings with Stroke n-gram Information":{"venue":"AAAI","authors":"Shaosheng Cao, Wei Lu, Jun Zhou and Xiaolong Li","paper":"http://www.statnlp.org/wp-content/uploads/papers/2018/cw2vec/cw2vec.pdf","bibtext":"@InProceedings{cao-lu-zhou-li:2018:AAAI2018,\\nauthor    = {Shaosheng Cao, Wei Lu, Jun Zhou and Xiaolong Li},\\ntitle     = {cw2vec: Learning Chinese Word Embeddings with Stroke n-gram Information},\\nyear      = {2018},\\nabstract  = {We propose cw2vec, a novel method for learning Chinese word embeddings.\\n It is based on our observation that exploiting stroke-level information is crucial\\nfor improving the learning of Chinese word embeddings. Specifically, we design a minimalist\\napproach to exploit such features, by using stroke n-grams, which capture semantic and\\nmorphological level information of Chinese words. Through qualitative analysis, we demonstrate that\\nour model is able to extract semantic information that cannot be captured by existing methods.\\nmorphological. Empirical results on the word similarity, word analogy, text classification and\\nnamed entity recognition tasks show that the proposed approach consistently outperforms\\nstate-of-the-art approaches such as word-based word2vec and GloVe, character-based CWE,\\ncomponent-based JWE and pixel-based GWE.}\\n}","code":""},"Learning Latent Opinions for Aspect-level Sentiment Classification":{"venue":"AAAI","authors":"Bailin Wang and Wei Lu","paper":"http://www.statnlp.org/wp-content/uploads/papers/2018/Learning-Latent/absa.pdf","bibtext":"@InAAAI{bailin-lu:2018:AAAI2018,\\nauthor    = {Bailin, Wang  and  Lu, Wei},\\ntitle     = {Learning Latent Opinions for Aspect-level Sentiment Classification},\\nyear      = {2018},\\nabstract  = {Aspect-level sentiment classification aims at detecting the sentiment expressed\\ntowards a particular target in a sentence. Based on the observation that the sentiment\\npolarity is often related to specific spans in the given sentence, it is possible to make\\nuse of such information for better classification. On the other hand, such information\\ncan also serve as justifications associated with the predictions. We propose a segmentation\\nattention based LSTM model which can effectively capture the structural dependencies between\\nthe target and the sentiment expressions with a linear-chain conditional random field (CRF) layer.\\nThe model simulates human’s process of inferring sentiment information when reading: when given a\\ntarget, humans tend to search for surrounding relevant text spans in the sentence before making an\\ninformed decision on the underlying sentiment information. We perform sentiment classification tasks\\non publicly available datasets on online reviews across different languages from SemEval tasks and\\nsocial comments from Twitter. Extensive experiments show that our model achieves the\\nstate-of-the-art performance while extracting interpretable sentiment expressions.}\\n}","code":"https://github.com/berlino/SA-Sent"}},"2019":{"Text2Math: End-to-end Parsing Text into Math Expressions":{"venue":"EMNLP","authors":"Yanyan Zou and Wei Lu","paper":"https://github.com/statnlp-research/statnlp-papers/blob/master/2019/Seq2Math.pdf","bibtext":"@InProceedings{zou19text2math,\\nauthor    = {Zou, Yanyan and Lu, Wei},\\ntitle     = {Text2Math: End-to-end Parsing Text into Math Expressions},\\nbooktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},\\nyear      = {2019}\\n}","code":"https://github.com/zoezou2015/text2math"},"Aligning Cross-lingual Entities with Multi-Aspect Information":{"venue":"EMNLP","authors":"Hsiu-Wei Yang∗, Yanyan Zou∗, Peng Shi∗, Wei Lu, Jimmy Lin, and Xu Sun","paper":"https://github.com/statnlp-research/statnlp-papers/blob/master/2019/Cross_ligual_Entity_Alignment.pdf","bibtext":"@InProceedings{zou19align,\\nauthor    = {Yang, Hsiu-Wei and Zou, Yanyan and Shi, Peng and Lu, Wei and Lin, Jimmy and Sun, Xu},\\ntitle     = {Aligning Cross-lingual Entities with Multi-Aspect Information},\\nbooktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},\\nyear      = {2019}\\n}","code":"https://github.com/h324yang/HMAN"},"Learning Explicit and Implicit Structures for Targeted Sentiment Analysis":{"venue":"EMNLP","authors":"Hao Li and Wei Lu","paper":"https://github.com/statnlp-research/statnlp-papers/blob/master/2019/emnlp2019-targetsentiment.pdf","bibtext":"@InProceedings{li2019sentiment,\\nauthor    = {Li, Hao  and  Lu, Wei},\\ntitle     = {Learning Explicit and Implicit Structures for Targeted Sentiment Analysis},\\nbooktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},\\nyear      = {2019}\\n}","code":"https://github.com/leodotnet/ei"},"Combining Spans into Entities: A Neural Two-Stage Approach for Recognizing Discontiguous Entities":{"venue":"EMNLP","authors":"Bailin Wang and Wei Lu","paper":"https://github.com/statnlp-research/statnlp-papers/blob/master/2019/bailinemnlp2019-disco.pdf","bibtext":"@InProceedings{wang2019combining,\\nauthor    = {Wang, Bailin  and  Lu, Wei},\\ntitle     = {Combining Spans into Entities: A Neural Two-Stage Approach for Recognizing Discontiguous Entities},\\nbooktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},\\nyear      = {2019}\\n}","code":"https://github.com/berlino/disco_em19"},"Dependency-Guided LSTM-CRF for Named Entity Recognition":{"venue":"EMNLP","authors":"Zhanming Jie and Wei Lu","paper":"http://www.statnlp.org/research/ie/jie2019depner.pdf","bibtext":"@InProceedings{jie2019dependency,\\nauthor    = {Jie, Zhanming  and  Lu, Wei},\\ntitle     = {Dependency-Guided LSTM-CRF for Named Entity Recognition},\\nbooktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},\\nyear      = {2019}\\n}","code":"https://github.com/allanj/ner_with_dependency"},"A Neural Multi-digraph Model for Chinese NER with Gazetteers":{"venue":"ACL","authors":"Ruixue Ding, Pengjun Xie, Xiaoyan Zhang, Wei Lu, Linlin Li and Luo Si","paper":"http://www.statnlp.org/research/ta/ruixue-acl19-ner.pdf","bibtext":"@inproceedings{ruixue2019,\\ntitle={A Neural Multi-digraph Model for Chinese NER with Gazetteers},\\nauthor={Ding, Ruixue and Xie, Pengjun and Zhang, Xiaoyan and Lu, Wei and Li, Linlin and Si, Luo},\\nbooktitle={Proceedings of ACL},\\nyear={2019}\\n}","code":"https://github.com/PhantomGrapes/MultiDigraphNER"},"Twitter Homophily: Network Based Prediction of User’s Occupation":{"venue":"ACL","authors":"Jiaqi Pan*, Rishabh Bhardwaj*, Wei Lu, Hai Leong Chieu, Xinghao Pan and Ni Yi Puay","paper":"http://www.statnlp.org/research/ta/jiaqi19acl-homophily.pdf","bibtext":"@InProceedings{pan-19-homophily,\\nauthor = {Pan, Jiaqi and Bhardwaj, Rishabh and Lu, Wei and Chieu, Hai Leong and Pan, Xinghao and Puay, Ni Yi},\\ntitle = {Twitter Homophily: Network Based Prediction of User’s Occupation},\\nbooktitle = {Proceedings of ACL},\\nyear = {2019}\\n}","code":"https://github.com/jqnap/Twitter-Occupation-Prediction"},"Quantity Tagger: A Latent-Variable Sequence Labeling Approach to Solving Addition-Subtraction Word Problems":{"venue":"ACL","authors":"Yanyan Zou and Wei Lu","paper":"http://www.statnlp.org/research/ta/yanyan-acl19-addsub.pdf","bibtext":"@InProceedings{zou-19-qt,\\nauthor = {Zou, Yanyan and Lu, Wei},\\ntitle = {Quantity Tagger: A Latent-Variable Sequence Labeling\\nApproach toSolving Addition-Subtraction Word Problems},\\nbooktitle = {Proceedings of ACL},\\nyear = {2019}\\n}","code":"https://github.com/zoezou2015/quantity_tagger"},"Attention Guided Graph Convolutional Networks for Relation Extraction":{"venue":"ACL","authors":"Zhijiang Guo*, Yan Zhang* and Wei Lu","paper":"http://www.statnlp.org/wp-content/uploads/2019/06/AGGCN.pdf","bibtext":"@inproceedings{guo-etal-2019-attention,\\r\\n    title = \\"Attention Guided Graph Convolutional Networks for Relation Extraction\\",\\r\\n    author = \\"Guo, Zhijiang  and\\r\\n      Zhang, Yan  and\\r\\n      Lu, Wei\\",\\r\\n    booktitle = \\"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics\\",\\r\\n    month = jul,\\r\\n    year = \\"2019\\",\\r\\n    address = \\"Florence, Italy\\",\\r\\n    publisher = \\"Association for Computational Linguistics\\",\\r\\n    doi = \\"10.18653/v1/P19-1024\\",\\r\\n    pages = \\"241--251\\",\\r\\n    abstract = \\"Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.\\",\\r\\n}","code":"https://github.com/Cartus/AGGCN_TACRED"},"Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning":{"venue":"TACL","authors":"Zhijiang Guo*, Yan Zhang*, Zhiyang Teng and Wei Lu","paper":"http://www.statnlp.org/wp-content/uploads/2019/03/DCGCN.pdf","bibtext":"@article{dcgcnforgraph2seq19guo,\\ntitle={Densely Connected Graph Convolutional Networks for Graph-to-Sequence Learning},\\nauthor={Zhijiang Guo and Yan Zhang and Zhiyang Teng and Wei Lu},\\njournal={Transactions of the Association of Computational Linguistics},\\n year={2019},\\n}","code":"https://github.com/Cartus/DCGCN"},"Joint Detection and Location of English Puns":{"venue":"NAACL","authors":"Yanyan Zou and Wei Lu","paper":"http://www.statnlp.org/research/ta/yanyan19naacl-pun.pdf","bibtext":"@InProceedings{zou-19-joint,\\nauthor    = {Zou, Yanyan and Lu, Wei},\\ntitle     = {Joint Detection and Location of English Puns},\\nbooktitle = {Proceedings of NAACL},\\nyear={2019}\\n}","code":"https://github.com/zoezou2015/PunLocation"},"Better Modeling of Incomplete Annotations for Named Entity Recognition":{"venue":"NAACL","authors":"Zhanming Jie, Pengjun Xie, Wei Lu, Ruixue Ding and Linlin Li","paper":"http://www.statnlp.org/research/ie/zhanming19naacl-ner.pdf","bibtext":"@inproceedings{jie2019better,\\ntitle={Better Modeling of Incomplete Annotations for Named Entity Recognition},\\nauthor={Jie, Zhanming and Xie, Pengjun and Lu, Wei and Ding, Ruixue and Li, Linlin},\\nbooktitle={Proceedings of NAACL},\\nyear={2019}\\n}","code":"https://github.com/allanj/ner_incomplete_annotation"},"Neural Chinese Address Parsing":{"venue":"NAACL","authors":"Hao Li, Wei Lu, Pengjun Xie and Linlin Li","paper":"http://www.statnlp.org/research/sp/lihao19naacl-address.pdf","bibtext":"@InProceedings{chineseaddressparsing19li,\\nauthor = \\"Li, Hao and Lu, Wei and Xie, Pengjun and Li, Linlin\\",\\ntitle = \\"Neural Chinese Address Parsing\\",\\nbooktitle = \\"Proc. of NAACL\\",\\nyear = \\"2019\\",\\n}","code":"https://github.com/leodotnet/neural-chinese-address-parsing/"}}}')},"9jPY":function(e,n,t){"use strict";var a=t("wx14"),o=t("Ff2n"),i=t("q1tI"),r=t.n(i),s=(t("17x9"),t("iuhU")),l=t("H2TA"),c=t("NqtD"),d=r.a.forwardRef((function(e,n){var t=e.children,i=e.classes,l=e.className,d=e.color,u=void 0===d?"inherit":d,p=e.component,g=void 0===p?"svg":p,h=e.fontSize,m=void 0===h?"default":h,b=e.htmlColor,f=e.titleAccess,y=e.viewBox,w=void 0===y?"0 0 24 24":y,L=Object(o.a)(e,["children","classes","className","color","component","fontSize","htmlColor","titleAccess","viewBox"]);return r.a.createElement(g,Object(a.a)({className:Object(s.a)(i.root,l,"inherit"!==u&&i["color".concat(Object(c.a)(u))],"default"!==m&&i["fontSize".concat(Object(c.a)(m))]),focusable:"false",viewBox:w,color:b,"aria-hidden":f?"false":"true",role:f?"img":"presentation",ref:n},L),t,f?r.a.createElement("title",null,f):null)}));d.muiName="SvgIcon";var u=Object(l.a)((function(e){return{root:{userSelect:"none",width:"1em",height:"1em",display:"inline-block",fill:"currentColor",flexShrink:0,fontSize:e.typography.pxToRem(24),transition:e.transitions.create("fill",{duration:e.transitions.duration.shorter})},colorPrimary:{color:e.palette.primary.main},colorSecondary:{color:e.palette.secondary.main},colorAction:{color:e.palette.action.active},colorError:{color:e.palette.error.main},colorDisabled:{color:e.palette.action.disabled},fontSizeInherit:{fontSize:"inherit"},fontSizeSmall:{fontSize:e.typography.pxToRem(20)},fontSizeLarge:{fontSize:e.typography.pxToRem(35)}}}),{name:"MuiSvgIcon"})(d);var p,g,h=(p=r.a.createElement("path",{d:"M12 2C6.47 2 2 6.47 2 12s4.47 10 10 10 10-4.47 10-10S17.53 2 12 2zm5 13.59L15.59 17 12 13.41 8.41 17 7 15.59 10.59 12 7 8.41 8.41 7 12 10.59 15.59 7 17 8.41 13.41 12 17 15.59z"}),(g=r.a.memo(r.a.forwardRef((function(e,n){return r.a.createElement(u,Object(a.a)({},e,{ref:n}),p)})))).muiName=u.muiName,g),m=t("ye/S"),b=t("bfFb"),f=t("VD++"),y=r.a.forwardRef((function(e,n){var t=e.avatar,i=e.classes,l=e.className,d=e.clickable,u=e.color,p=void 0===u?"default":u,g=e.component,m=e.deleteIcon,y=e.disabled,w=void 0!==y&&y,L=e.icon,v=e.label,C=e.onClick,x=e.onDelete,A=e.onKeyUp,S=e.size,P=void 0===S?"medium":S,E=e.variant,k=void 0===E?"default":E,N=Object(o.a)(e,["avatar","classes","className","clickable","color","component","deleteIcon","disabled","icon","label","onClick","onDelete","onKeyUp","size","variant"]),W=r.a.useRef(null),M=Object(b.a)(W,n),O=function(e){e.stopPropagation(),x&&x(e)},j=!(!1===d||!C)||d,I="small"===P,R=g||(j?f.a:"div"),z=R===f.a?{component:"div"}:{},T=null;if(x){var D=Object(s.a)("default"!==p&&("default"===k?i["deleteIconColor".concat(Object(c.a)(p))]:i["deleteIconOutlinedColor".concat(Object(c.a)(p))]),I&&i.deleteIconSmall);T=m&&r.a.isValidElement(m)?r.a.cloneElement(m,{className:Object(s.a)(m.props.className,i.deleteIcon,D),onClick:O}):r.a.createElement(h,{className:Object(s.a)(i.deleteIcon,D),onClick:O})}var H=null;t&&r.a.isValidElement(t)&&(H=r.a.cloneElement(t,{className:Object(s.a)(i.avatar,t.props.className,I&&i.avatarSmall,"default"!==p&&i["avatarColor".concat(Object(c.a)(p))])}));var G=null;return L&&r.a.isValidElement(L)&&(G=r.a.cloneElement(L,{className:Object(s.a)(i.icon,L.props.className,I&&i.iconSmall,"default"!==p&&i["iconColor".concat(Object(c.a)(p))])})),r.a.createElement(R,Object(a.a)({role:j||x?"button":void 0,className:Object(s.a)(i.root,l,"default"!==p&&[i["color".concat(Object(c.a)(p))],j&&i["clickableColor".concat(Object(c.a)(p))],x&&i["deletableColor".concat(Object(c.a)(p))]],"default"!==k&&[i.outlined,{primary:i.outlinedPrimary,secondary:i.outlinedSecondary}[p]],w&&i.disabled,I&&i.sizeSmall,j&&i.clickable,x&&i.deletable),"aria-disabled":!!w||void 0,tabIndex:j||x?0:void 0,onClick:C,onKeyUp:function(e){if(A&&A(e),e.currentTarget===e.target){var n=e.key;!x||"Backspace"!==n&&"Delete"!==n?"Escape"===n&&W.current&&W.current.blur():x(e)}},ref:M},z,N),H||G,r.a.createElement("span",{className:Object(s.a)(i.label,I&&i.labelSmall)},v),T)}));n.a=Object(l.a)((function(e){var n="light"===e.palette.type?e.palette.grey[300]:e.palette.grey[700],t=Object(m.c)(e.palette.text.primary,.26);return{root:{fontFamily:e.typography.fontFamily,fontSize:e.typography.pxToRem(13),display:"inline-flex",alignItems:"center",justifyContent:"center",height:32,color:e.palette.getContrastText(n),backgroundColor:n,borderRadius:16,whiteSpace:"nowrap",transition:e.transitions.create(["background-color","box-shadow"]),cursor:"default",outline:0,textDecoration:"none",border:"none",padding:0,verticalAlign:"middle",boxSizing:"border-box","&$disabled":{opacity:.5,pointerEvents:"none"},"& $avatar":{marginLeft:5,marginRight:-6,width:24,height:24,color:"light"===e.palette.type?e.palette.grey[700]:e.palette.grey[300],fontSize:e.typography.pxToRem(12)},"& $avatarColorPrimary":{color:e.palette.primary.contrastText,backgroundColor:e.palette.primary.dark},"& $avatarColorSecondary":{color:e.palette.secondary.contrastText,backgroundColor:e.palette.secondary.dark},"& $avatarSmall":{marginLeft:4,marginRight:-4,width:18,height:18,fontSize:e.typography.pxToRem(10)}},sizeSmall:{height:24},colorPrimary:{backgroundColor:e.palette.primary.main,color:e.palette.primary.contrastText},colorSecondary:{backgroundColor:e.palette.secondary.main,color:e.palette.secondary.contrastText},disabled:{},clickable:{userSelect:"none",WebkitTapHighlightColor:"transparent",cursor:"pointer","&:hover, &:focus":{backgroundColor:Object(m.b)(n,.08)},"&:active":{boxShadow:e.shadows[1]}},clickableColorPrimary:{"&:hover, &:focus":{backgroundColor:Object(m.b)(e.palette.primary.main,.08)}},clickableColorSecondary:{"&:hover, &:focus":{backgroundColor:Object(m.b)(e.palette.secondary.main,.08)}},deletable:{"&:focus":{backgroundColor:Object(m.b)(n,.08)}},deletableColorPrimary:{"&:focus":{backgroundColor:Object(m.b)(e.palette.primary.main,.2)}},deletableColorSecondary:{"&:focus":{backgroundColor:Object(m.b)(e.palette.secondary.main,.2)}},outlined:{backgroundColor:"transparent",border:"1px solid ".concat("light"===e.palette.type?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)"),"$clickable&:hover, $clickable&:focus, $deletable&:focus":{backgroundColor:Object(m.c)(e.palette.text.primary,e.palette.action.hoverOpacity)},"& $avatar":{marginLeft:4},"& $avatarSmall":{marginLeft:2},"& $icon":{marginLeft:4},"& $iconSmall":{marginLeft:2},"& $deleteIcon":{marginRight:5},"& $deleteIconSmall":{marginRight:3}},outlinedPrimary:{color:e.palette.primary.main,border:"1px solid ".concat(e.palette.primary.main),"$clickable&:hover, $clickable&:focus, $deletable&:focus":{backgroundColor:Object(m.c)(e.palette.primary.main,e.palette.action.hoverOpacity)}},outlinedSecondary:{color:e.palette.secondary.main,border:"1px solid ".concat(e.palette.secondary.main),"$clickable&:hover, $clickable&:focus, $deletable&:focus":{backgroundColor:Object(m.c)(e.palette.secondary.main,e.palette.action.hoverOpacity)}},avatar:{},avatarSmall:{},avatarColorPrimary:{},avatarColorSecondary:{},icon:{color:"light"===e.palette.type?e.palette.grey[700]:e.palette.grey[300],marginLeft:5,marginRight:-6},iconSmall:{width:18,height:18,marginLeft:4,marginRight:-4},iconColorPrimary:{color:"inherit"},iconColorSecondary:{color:"inherit"},label:{display:"flex",alignItems:"center",paddingLeft:12,paddingRight:12,whiteSpace:"nowrap"},labelSmall:{paddingLeft:8,paddingRight:8},deleteIcon:{WebkitTapHighlightColor:"transparent",color:t,height:22,width:22,cursor:"pointer",margin:"0 5px 0 -6px","&:hover":{color:Object(m.c)(t,.4)}},deleteIconSmall:{height:16,width:16,marginRight:4,marginLeft:-4},deleteIconColorPrimary:{color:Object(m.c)(e.palette.primary.contrastText,.7),"&:hover, &:active":{color:e.palette.primary.contrastText}},deleteIconColorSecondary:{color:Object(m.c)(e.palette.secondary.contrastText,.7),"&:hover, &:active":{color:e.palette.secondary.contrastText}},deleteIconOutlinedColorPrimary:{color:Object(m.c)(e.palette.primary.main,.7),"&:hover, &:active":{color:e.palette.primary.main}},deleteIconOutlinedColorSecondary:{color:Object(m.c)(e.palette.secondary.main,.7),"&:hover, &:active":{color:e.palette.secondary.main}}}}),{name:"MuiChip"})(y)},E9nw:function(e,n,t){t("8+KV"),e.exports=function(){var e=document.getSelection();if(!e.rangeCount)return function(){};for(var n=document.activeElement,t=[],a=0;a<e.rangeCount;a++)t.push(e.getRangeAt(a));switch(n.tagName.toUpperCase()){case"INPUT":case"TEXTAREA":n.blur();break;default:n=null}return e.removeAllRanges(),function(){"Caret"===e.type&&e.removeAllRanges(),e.rangeCount||t.forEach((function(n){e.addRange(n)})),n&&n.focus()}}},P5Jw:function(e,n,t){"use strict";var a=t("rHrb").CopyToClipboard;a.CopyToClipboard=a,e.exports=a},WLL4:function(e,n,t){var a=t("XKFU");a(a.S+a.F*!t("nh4g"),"Object",{defineProperties:t("FJW5")})},Z3vd:function(e,n,t){"use strict";var a=t("Ff2n"),o=t("wx14"),i=t("q1tI"),r=t.n(i),s=(t("17x9"),t("iuhU")),l=t("H2TA"),c=t("ye/S"),d=t("VD++"),u=t("NqtD"),p=r.a.forwardRef((function(e,n){var t=e.children,i=e.classes,l=e.className,c=e.color,p=void 0===c?"default":c,g=e.component,h=void 0===g?"button":g,m=e.disabled,b=void 0!==m&&m,f=e.disableFocusRipple,y=void 0!==f&&f,w=e.endIcon,L=e.focusVisibleClassName,v=e.fullWidth,C=void 0!==v&&v,x=e.size,A=void 0===x?"medium":x,S=e.startIcon,P=e.type,E=void 0===P?"button":P,k=e.variant,N=void 0===k?"text":k,W=Object(a.a)(e,["children","classes","className","color","component","disabled","disableFocusRipple","endIcon","focusVisibleClassName","fullWidth","size","startIcon","type","variant"]),M=S&&r.a.createElement("span",{className:Object(s.a)(i.startIcon,i["iconSize".concat(Object(u.a)(A))])},S),O=w&&r.a.createElement("span",{className:Object(s.a)(i.endIcon,i["iconSize".concat(Object(u.a)(A))])},w);return r.a.createElement(d.a,Object(o.a)({className:Object(s.a)(i.root,i[N],l,"inherit"===p?i.colorInherit:"default"!==p&&i["".concat(N).concat(Object(u.a)(p))],"medium"!==A&&[i["".concat(N,"Size").concat(Object(u.a)(A))],i["size".concat(Object(u.a)(A))]],b&&i.disabled,C&&i.fullWidth),component:h,disabled:b,focusRipple:!y,focusVisibleClassName:Object(s.a)(i.focusVisible,L),ref:n,type:E},W),r.a.createElement("span",{className:i.label},M,t,O))}));n.a=Object(l.a)((function(e){return{root:Object(o.a)({},e.typography.button,{boxSizing:"border-box",minWidth:64,padding:"6px 16px",borderRadius:e.shape.borderRadius,color:e.palette.text.primary,transition:e.transitions.create(["background-color","box-shadow","border"],{duration:e.transitions.duration.short}),"&:hover":{textDecoration:"none",backgroundColor:Object(c.c)(e.palette.text.primary,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"},"&$disabled":{backgroundColor:"transparent"}},"&$disabled":{color:e.palette.action.disabled}}),label:{width:"100%",display:"inherit",alignItems:"inherit",justifyContent:"inherit"},text:{padding:"6px 8px"},textPrimary:{color:e.palette.primary.main,"&:hover":{backgroundColor:Object(c.c)(e.palette.primary.main,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},textSecondary:{color:e.palette.secondary.main,"&:hover":{backgroundColor:Object(c.c)(e.palette.secondary.main,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},outlined:{padding:"5px 15px",border:"1px solid ".concat("light"===e.palette.type?"rgba(0, 0, 0, 0.23)":"rgba(255, 255, 255, 0.23)"),"&$disabled":{border:"1px solid ".concat(e.palette.action.disabled)}},outlinedPrimary:{color:e.palette.primary.main,border:"1px solid ".concat(Object(c.c)(e.palette.primary.main,.5)),"&:hover":{border:"1px solid ".concat(e.palette.primary.main),backgroundColor:Object(c.c)(e.palette.primary.main,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}}},outlinedSecondary:{color:e.palette.secondary.main,border:"1px solid ".concat(Object(c.c)(e.palette.secondary.main,.5)),"&:hover":{border:"1px solid ".concat(e.palette.secondary.main),backgroundColor:Object(c.c)(e.palette.secondary.main,e.palette.action.hoverOpacity),"@media (hover: none)":{backgroundColor:"transparent"}},"&$disabled":{border:"1px solid ".concat(e.palette.action.disabled)}},contained:{color:e.palette.getContrastText(e.palette.grey[300]),backgroundColor:e.palette.grey[300],boxShadow:e.shadows[2],"&:hover":{backgroundColor:e.palette.grey.A100,boxShadow:e.shadows[4],"@media (hover: none)":{boxShadow:e.shadows[2],backgroundColor:e.palette.grey[300]},"&$disabled":{backgroundColor:e.palette.action.disabledBackground}},"&$focusVisible":{boxShadow:e.shadows[6]},"&:active":{boxShadow:e.shadows[8]},"&$disabled":{color:e.palette.action.disabled,boxShadow:e.shadows[0],backgroundColor:e.palette.action.disabledBackground}},containedPrimary:{color:e.palette.primary.contrastText,backgroundColor:e.palette.primary.main,"&:hover":{backgroundColor:e.palette.primary.dark,"@media (hover: none)":{backgroundColor:e.palette.primary.main}}},containedSecondary:{color:e.palette.secondary.contrastText,backgroundColor:e.palette.secondary.main,"&:hover":{backgroundColor:e.palette.secondary.dark,"@media (hover: none)":{backgroundColor:e.palette.secondary.main}}},focusVisible:{},disabled:{},colorInherit:{color:"inherit",borderColor:"currentColor"},textSizeSmall:{padding:"4px 5px",fontSize:e.typography.pxToRem(13)},textSizeLarge:{padding:"8px 11px",fontSize:e.typography.pxToRem(15)},outlinedSizeSmall:{padding:"3px 9px",fontSize:e.typography.pxToRem(13)},outlinedSizeLarge:{padding:"7px 21px",fontSize:e.typography.pxToRem(15)},containedSizeSmall:{padding:"4px 10px",fontSize:e.typography.pxToRem(13)},containedSizeLarge:{padding:"8px 22px",fontSize:e.typography.pxToRem(15)},sizeSmall:{},sizeLarge:{},fullWidth:{width:"100%"},startIcon:{display:"inherit",marginRight:8,marginLeft:-4,"&$iconSizeSmall":{marginLeft:-2}},endIcon:{display:"inherit",marginRight:-4,marginLeft:8,"&$iconSizeSmall":{marginRight:-2}},iconSizeSmall:{"& > *:first-child":{fontSize:18}},iconSizeMedium:{"& > *:first-child":{fontSize:20}},iconSizeLarge:{"& > *:first-child":{fontSize:22}}}}),{name:"MuiButton"})(p)},jm62:function(e,n,t){var a=t("XKFU"),o=t("mQtv"),i=t("aCFj"),r=t("EemH"),s=t("8a7r");a(a.S,"Object",{getOwnPropertyDescriptors:function(e){for(var n,t,a=i(e),l=r.f,c=o(a),d={},u=0;c.length>u;)void 0!==(t=l(a,n=c[u++]))&&s(d,n,t);return d}})},mQtv:function(e,n,t){var a=t("kJMx"),o=t("JiEa"),i=t("y3w9"),r=t("dyZX").Reflect;e.exports=r&&r.ownKeys||function(e){var n=a.f(i(e)),t=o.f;return t?n.concat(t(e)):n}},o4QW:function(e,n,t){"use strict";var a=t("wx14"),o=t("Ff2n"),i=t("q1tI"),r=t.n(i),s=(t("17x9"),t("iuhU")),l=t("H2TA"),c=r.a.forwardRef((function(e,n){var t=e.disableSpacing,i=void 0!==t&&t,l=e.classes,c=e.className,d=Object(o.a)(e,["disableSpacing","classes","className"]);return r.a.createElement("div",Object(a.a)({className:Object(s.a)(l.root,c,!i&&l.spacing),ref:n},d))}));n.a=Object(l.a)({root:{display:"flex",alignItems:"center",padding:8},spacing:{"& > :not(:first-child)":{marginLeft:8}}},{name:"MuiCardActions"})(c)},rHrb:function(e,n,t){"use strict";t("hHhE"),t("/SS/"),t("V+eJ"),t("WLL4"),t("jm62"),t("8+KV"),t("0l/t"),t("rGqo"),t("yt8O"),t("Btvt"),t("RW0V"),t("rE2o"),t("ioFf"),t("HAE/"),Object.defineProperty(n,"__esModule",{value:!0}),n.CopyToClipboard=void 0;var a=i(t("q1tI")),o=i(t("+QRC"));function i(e){return e&&e.__esModule?e:{default:e}}function r(e){return(r="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e})(e)}function s(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}function c(e,n){for(var t=0;t<n.length;t++){var a=n[t];a.enumerable=a.enumerable||!1,a.configurable=!0,"value"in a&&(a.writable=!0),Object.defineProperty(e,a.key,a)}}function d(e){return(d=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)})(e)}function u(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function p(e,n){return(p=Object.setPrototypeOf||function(e,n){return e.__proto__=n,e})(e,n)}function g(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}var h=function(e){function n(){var e,t,i,s;!function(e,n){if(!(e instanceof n))throw new TypeError("Cannot call a class as a function")}(this,n);for(var l=arguments.length,c=new Array(l),p=0;p<l;p++)c[p]=arguments[p];return i=this,s=(e=d(n)).call.apply(e,[this].concat(c)),t=!s||"object"!==r(s)&&"function"!=typeof s?u(i):s,g(u(t),"onClick",(function(e){var n=t.props,i=n.text,r=n.onCopy,s=n.children,l=n.options,c=a.default.Children.only(s),d=(0,o.default)(i,l);r&&r(i,d),c&&c.props&&"function"==typeof c.props.onClick&&c.props.onClick(e)})),t}var t,i,h;return function(e,n){if("function"!=typeof n&&null!==n)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(n&&n.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),n&&p(e,n)}(n,e),t=n,(i=[{key:"render",value:function(){var e=this.props,n=(e.text,e.onCopy,e.options,e.children),t=l(e,["text","onCopy","options","children"]),o=a.default.Children.only(n);return a.default.cloneElement(o,function(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?s(t,!0).forEach((function(n){g(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(t).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}({},t,{onClick:this.onClick}))}}])&&c(t.prototype,i),h&&c(t,h),n}(a.default.PureComponent);n.CopyToClipboard=h,g(h,"defaultProps",{onCopy:void 0,options:void 0})},wHSu:function(e,n,t){"use strict";t.d(n,"a",(function(){return a})),t.d(n,"b",(function(){return o})),t.d(n,"c",(function(){return i})),t.d(n,"d",(function(){return r}));var a={prefix:"fas",iconName:"copy",icon:[448,512,[],"f0c5","M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z"]},o={prefix:"fas",iconName:"download",icon:[512,512,[],"f019","M216 0h80c13.3 0 24 10.7 24 24v168h87.7c17.8 0 26.7 21.5 14.1 34.1L269.7 378.3c-7.5 7.5-19.8 7.5-27.3 0L90.1 226.1c-12.6-12.6-3.7-34.1 14.1-34.1H192V24c0-13.3 10.7-24 24-24zm296 376v112c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V376c0-13.3 10.7-24 24-24h146.7l49 49c20.1 20.1 52.5 20.1 72.6 0l49-49H488c13.3 0 24 10.7 24 24zm-124 88c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20zm64 0c0-11-9-20-20-20s-20 9-20 20 9 20 20 20 20-9 20-20z"]},i={prefix:"fas",iconName:"external-link-alt",icon:[512,512,[],"f35d","M432,320H400a16,16,0,0,0-16,16V448H64V128H208a16,16,0,0,0,16-16V80a16,16,0,0,0-16-16H48A48,48,0,0,0,0,112V464a48,48,0,0,0,48,48H400a48,48,0,0,0,48-48V336A16,16,0,0,0,432,320ZM488,0h-128c-21.37,0-32.05,25.91-17,41l35.73,35.73L135,320.37a24,24,0,0,0,0,34L157.67,377a24,24,0,0,0,34,0L435.28,133.32,471,169c15,15,41,4.5,41-17V24A24,24,0,0,0,488,0Z"]},r={prefix:"fas",iconName:"file-code",icon:[384,512,[],"f1c9","M384 121.941V128H256V0h6.059c6.365 0 12.47 2.529 16.971 7.029l97.941 97.941A24.005 24.005 0 0 1 384 121.941zM248 160c-13.2 0-24-10.8-24-24V0H24C10.745 0 0 10.745 0 24v464c0 13.255 10.745 24 24 24h336c13.255 0 24-10.745 24-24V160H248zM123.206 400.505a5.4 5.4 0 0 1-7.633.246l-64.866-60.812a5.4 5.4 0 0 1 0-7.879l64.866-60.812a5.4 5.4 0 0 1 7.633.246l19.579 20.885a5.4 5.4 0 0 1-.372 7.747L101.65 336l40.763 35.874a5.4 5.4 0 0 1 .372 7.747l-19.579 20.884zm51.295 50.479l-27.453-7.97a5.402 5.402 0 0 1-3.681-6.692l61.44-211.626a5.402 5.402 0 0 1 6.692-3.681l27.452 7.97a5.4 5.4 0 0 1 3.68 6.692l-61.44 211.626a5.397 5.397 0 0 1-6.69 3.681zm160.792-111.045l-64.866 60.812a5.4 5.4 0 0 1-7.633-.246l-19.58-20.885a5.4 5.4 0 0 1 .372-7.747L284.35 336l-40.763-35.874a5.4 5.4 0 0 1-.372-7.747l19.58-20.885a5.4 5.4 0 0 1 7.633-.246l64.866 60.812a5.4 5.4 0 0 1-.001 7.879z"]}}}]);
//# sourceMappingURL=component---src-pages-publications-js-267dbbd2665f8bbff6ab.js.map